# ScrubPrep
ğŸ“– Story Behind the Project
My sister is currently preparing for her postgraduate medical exams â€” and like many med students, she's buried in mountains of textbooks. One evening, as she struggled to find a quick answer to a clinical question, my cousin casually said, "Why not use AI for that?" Her response? ğŸ˜’ â€œAI doesnâ€™t get medicine.â€

Challenge accepted.

ScrubPrep was born out of a mission: to build an AI assistant that doesn't just guess, but actually knows â€” by pulling answers directly from her own medical textbooks. I wanted to prove that AI can help, when it's grounded in the right context.

ScrubPrep is a Retrieval-Augmented Generation (RAG) based chatbot that:
Accepts natural language medical questions ğŸ’¬
Retrieves context from uploaded textbook content ğŸ“š
Generates accurate, relevant, and easy-to-understand answers âœ¨

âš™ï¸ Tech Stack
LLM: Groq API / HuggingFace Transformers
RAG: LangChain + FAISS for semantic search
Vector Database: Pinecone for efficient semantic search and scalable vector indexing
Data: Custom-ingested medical textbooks (PDFs â†’ chunks)
Frontend: Streamlit (quick UI for chat)
Backend: FastAPI (modular and scalable)

ğŸ§ª How I Evaluated It
I worked with my sister to test it using real PG exam-style questions. Evaluation focused on:
ğŸ“Œ Relevance to textbook content
ğŸ“Œ Clarity and conciseness of explanation
ğŸ“Œ Trustworthiness â€” no hallucinations allowed!

ğŸ“ What I Learned
AI can be extremely helpful if it's grounded in the right data.
RAG architectures are incredibly powerful for domain-specific tasks.
Prompt engineering is just as important as model selection.
And most importantly... never underestimate a skeptical med student as a QA tester. ğŸ˜‰
